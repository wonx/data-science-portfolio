 # Data Science portfolio
Portfolio of data science projects completed by me for academic, self-learning, and hobby purposes.
- [GameGuard: A Machine Learning solution to protect gamers from microtransaction addiction](https://github.com/wonx/lootbox_addiction): GameGuard is a machine learning tool that monitors and mitigates addictive behavior in video games based on data from lootbox purchases, by applying a ML model trained on online gambling data. Its goal is to prevent microtransaction addiction and provide a solution for regulatory agencies and game developers to address the issue. Check the [online demo](http://gameguard.marcpalaus.com). *Tools: Python, Pandas, NumPy, scikit-learn, BeautifulSoup, Flask, Plotly.* 
- [Film recommender system](film-recommender-system): example of a recommender system, used to provide suggestions for items that better a particular use and predict their preferences. In this example, the recommender system is used to suggest movies to a particular user, based on the overall movie ratings and the taste of similar-minded users. *Tools: Python, Pandas, NumPy, Matplotlib, Jupyter Notebook.*
- [K-means chromosome size clustering](chromosomesize-kmeans-clustering/Main.ipynb) [![View Jupyter Notebook](https://img.shields.io/badge/view-Jupyter%20notebook-orange.svg)](chromosomesize-kmeans-clustering/Main.ipynb) (chromosome length): Determining the most appropiate way to cluster mice chromosomes according to their relative length in each cell, so the chromosome number can be easily inferred in the absence of other variables, through K-Means clustering. *Tools: R, ggplot2, Jupyter Notebook.* 
- [Chromosome distance ratio bootstrapping](chromosomedistance-data-boostrapping/Main.ipynb) [![View Jupyter Notebook](https://img.shields.io/badge/view-Jupyter%20notebook-orange.svg)](chromosomedistance-data-boostrapping/Main.ipynb) (chromosome end-to-end distance ratio): Hypothesis testing by comparing features across five chromosome clusters in two groups of mice (wildtype vs mutant). Since the distribution of the dataset did not fit a normal distribution, the bootstrapping method has been used to resample the available data to infer the confidence interval (CI) of the population. *Tools: Python, Pandas, Seaborn, Numpy, Matplotlib, sklearn.* 
- [Photo collection social network graph](pictures-socialnetwork/Main.ipynb) [![View Jupyter Notebook](https://img.shields.io/badge/view-Jupyter%20notebook-orange.svg)](pictures-socialnetwork/Main.ipynb) (digikam's picture database): Social network graph build using the collective metadata stored in a photo collection, using digiKam's sqlite3 database as a source. It computes the number of times two given people appear in a picture together, and computes an interactive social graph showing the relationships between all people present in the photo library (*sample 1:* [[static]](pictures-socialnetwork/socialgraph_trimmed_n1.png); *sample 2*: [[interactive]](http://www.marcpalaus.com/git_files/socialgraph_trimmed.html) [[static]](pictures-socialnetwork/socialgraph_trimmed.png)). It can also focus on a particular people and the relations in their closest circle of acquaintances (*sample*: [[interactive]](http://www.marcpalaus.com/git_files/socialgraph_Oíuajqn%20Rezpé%20Oedoml.html) [[static]](pictures-socialnetwork/socialgraph_Oíuajqn%20Rezpé%20Oedoml.png)), or filter the people based on any existing keyword in the database (*sample*: pictures labelled with "New York" or "Toronto" [[interactive]](http://www.marcpalaus.com/git_files/socialgraph_Toronto_New%20York.html) [[static]](pictures-socialnetwork/socialgraph_Toronto_New%20York.png)). *Tools: SQL, Python, Pandas, Seaborn, scikit-learn, pyvis.* 
- [Barcelona Live commuter rail map](https://github.com/wonx/rodalies-tracker): Real-time visualization created from train schedules in the [Barcelona metro area](https://en.wikipedia.org/wiki/Rodalies_de_Catalunya). The backend parses [GTFS](https://gtfs.org/) data to recreate the schedules, uses the [Tabula](https://tabula.technology/) Python library to parse tables in PDF, Pandas to store and clean the data, and is served as Flask web application that sends the train position data to the front-end, writen in JavaScript, CSS, and SVG. (*online-demo*: [[map-view]](http://rodalies.marcpalaus.com/map) [[line-view]](http://rodalies.marcpalaus.com/)). *Tools: Python, Tabula, Pandas, JavaScript, CSS, Flask.* 

- Machine learning:
  - [Linear regression](ecommerce-linear-regression/Main.ipynb) [![View Jupyter Notebook](https://img.shields.io/badge/view-Jupyter%20notebook-orange.svg)](ecommerce-linear-regression/Main.ipynb) (e-commerce dataset): Example of the use of a Linear Regression Model to predict sales based on numerical data on a simulated E-commerce setting. *Tools: Python, Pandas, SeaBorn, NumPy, Sklearn and Jupyter Notebook.* 
  - [Logistic regression](advertising-logistic-regression/Main.ipynb) [![View Jupyter Notebook](https://img.shields.io/badge/view-Jupyter%20notebook-orange.svg)](advertising-logistic-regression/Main.ipynb) (advertising dataset): Using a Logistic Regression Model to predict whether or not a user would click on an ad based on a series of features related to how a user browsed the company website. *Tools: Python, Pandas, SeaBorn, NumPy, Sklearn and Jupyter Notebook.* 
  - [K-Nearest-Neighbors](KNearestNeighbors-project/Main.ipynb) [![View Jupyter Notebook](https://img.shields.io/badge/view-Jupyter%20notebook-orange.svg)](KNearestNeighbors-project/Main.ipynb) (KNN-project-data dataset): Using the K-Nearest-Neighbors algorithm, we create a model to predict a binary categorical variable based on a series of cryptic numerical features. *Tools: Python, Pandas, SeaBorn, NumPy, Sklearn and Jupyter Notebook.* 
  - [Random Forest Classifier](lendingclub-randomforest/Main.ipynb) [![View Jupyter Notebook](https://img.shields.io/badge/view-Jupyter%20notebook-orange.svg)](lendingclub-randomforest/Main.ipynb) (Lending Club dataset): Predicting whether or not a borrower will fully repay a loan based on a series of financial features, comparing the performance of a Decision Tree classifier against a Random Forest Model. *Tools: Python, Pandas, SeaBorn, NumPy, Sklearn and Jupyter Notebook.* 
